{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ff29d29",
   "metadata": {},
   "source": [
    "# üìù Exercise M6.01\n",
    "\n",
    "The aim of this notebook is to investigate if we can tune the **hyperparameters\n",
    "of a bagging regressor** and evaluate the gain obtained.\n",
    "\n",
    "Let's load the **California housing dataset** and split it into a training and\n",
    "a testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b42d24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data, target = fetch_california_housing(as_frame=True, return_X_y=True)\n",
    "target *= 100  # rescale the target in k$\n",
    "data_train, data_test, target_train, target_test = train_test_split(\n",
    "    data, target, random_state=0, test_size=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0fe72e",
   "metadata": {},
   "source": [
    "<div class=\"admonition note alert alert-info\">\n",
    "<p class=\"first admonition-title\" style=\"font-weight: bold;\">Note</p>\n",
    "<p class=\"last\">If you want a deeper overview regarding this dataset, you can refer to the\n",
    "Appendix - Datasets description section at the end of this MOOC.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a916439",
   "metadata": {},
   "source": [
    "**Create a `BaggingRegressor`** and provide a **`DecisionTreeRegressor`**\n",
    "to its parameter **`base_estimator`**. **Train the regressor** and **evaluate its\n",
    "statistical performance** on the test set using the **mean absolute error** as a **metric**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3cf4e35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34.50338915697676"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "bagging = BaggingRegressor(\n",
    "    base_estimator=DecisionTreeRegressor(), \n",
    "    n_estimators=100, \n",
    "    random_state=42)\n",
    "\n",
    "bagging.fit(data_train, target_train, )\n",
    "pred = bagging.predict(data_test)\n",
    "mae = mean_absolute_error(target_test, pred)\n",
    "mae"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8729ddf3",
   "metadata": {},
   "source": [
    "Now, **create a `RandomizedSearchCV`** instance using the previous model and\n",
    "**tune the important parameters of the bagging regressor**. Find the best\n",
    "parameters  and check if you are able to find a set of parameters that\n",
    "improve the default regressor still using the mean absolute error as a\n",
    "metric.\n",
    "\n",
    "<div class=\"admonition tip alert alert-warning\">\n",
    "<p class=\"first admonition-title\" style=\"font-weight: bold;\">Tip</p>\n",
    "<p class=\"last\">You can list the bagging regressor's parameters using the <tt class=\"docutils literal\">get_params</tt>\n",
    "method.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6094f04a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'base_estimator__ccp_alpha': 0.0,\n",
       " 'base_estimator__criterion': 'mse',\n",
       " 'base_estimator__max_depth': None,\n",
       " 'base_estimator__max_features': None,\n",
       " 'base_estimator__max_leaf_nodes': None,\n",
       " 'base_estimator__min_impurity_decrease': 0.0,\n",
       " 'base_estimator__min_impurity_split': None,\n",
       " 'base_estimator__min_samples_leaf': 1,\n",
       " 'base_estimator__min_samples_split': 2,\n",
       " 'base_estimator__min_weight_fraction_leaf': 0.0,\n",
       " 'base_estimator__random_state': None,\n",
       " 'base_estimator__splitter': 'best',\n",
       " 'base_estimator': DecisionTreeRegressor(),\n",
       " 'bootstrap': True,\n",
       " 'bootstrap_features': False,\n",
       " 'max_features': 1.0,\n",
       " 'max_samples': 1.0,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': 42,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "bagging = BaggingRegressor(\n",
    "    base_estimator=DecisionTreeRegressor(), \n",
    "    n_estimators=100, \n",
    "    random_state=42)\n",
    "\n",
    "params = {'base_estimator__max_depth': [2,3,4,5,6,7,8,9]}\n",
    "# rnds = RandomizedSearchCV(bagging, )\n",
    "bagging.get_params()\n",
    "\n",
    "# {'base_estimator__ccp_alpha': 0.0,\n",
    "#  'base_estimator__criterion': 'mse',\n",
    "#  'base_estimator__max_depth': None,\n",
    "#  'base_estimator__max_features': None,\n",
    "#  'base_estimator__max_leaf_nodes': None,\n",
    "#  'base_estimator__min_impurity_decrease': 0.0,\n",
    "#  'base_estimator__min_impurity_split': None,\n",
    "#  'base_estimator__min_samples_leaf': 1,\n",
    "#  'base_estimator__min_samples_split': 2,\n",
    "#  'base_estimator__min_weight_fraction_leaf': 0.0,\n",
    "#  'base_estimator__random_state': None,\n",
    "#  'base_estimator__splitter': 'best',\n",
    "#  'base_estimator': DecisionTreeRegressor(),\n",
    "#  'bootstrap': True,\n",
    "#  'bootstrap_features': False,\n",
    "#  'max_features': 1.0,\n",
    "#  'max_samples': 1.0,\n",
    "#  'n_estimators': 100,\n",
    "#  'n_jobs': None,\n",
    "#  'oob_score': False,\n",
    "#  'random_state': 42,\n",
    "#  'verbose': 0,\n",
    "#  'warm_start': False}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e43aff4",
   "metadata": {},
   "source": [
    "We see that the bagging regressor provides a predictor in which **fine tuning\n",
    "is not as important as in the case of fitting a single decision tree**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02030cd8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "nbreset": "https://github.com/INRIA/scikit-learn-mooc/raw/master/notebooks/ensemble_ex_01.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
