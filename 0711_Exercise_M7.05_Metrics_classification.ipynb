{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7619ae20",
   "metadata": {},
   "source": [
    "# üìù Exercise M7.02\n",
    "\n",
    "We **presented different classification metrics** in the previous notebook.\n",
    "However, we **did not use it with a cross-validation**. This exercise aims at\n",
    "practicing and implementing cross-validation.\n",
    "\n",
    "We will reuse the **blood transfusion dataset**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "784ce3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "blood_transfusion = pd.read_csv(\"../datasets/blood_transfusion.csv\")\n",
    "data = blood_transfusion.drop(columns=\"Class\")\n",
    "target = blood_transfusion[\"Class\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7215b23a",
   "metadata": {},
   "source": [
    "<div class=\"admonition note alert alert-info\">\n",
    "<p class=\"first admonition-title\" style=\"font-weight: bold;\">Note</p>\n",
    "<p class=\"last\">If you want a deeper overview regarding this dataset, you can refer to the\n",
    "Appendix - Datasets description section at the end of this MOOC.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976a4fef",
   "metadata": {},
   "source": [
    "First, create a decision tree classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9163698",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "model = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ab57de",
   "metadata": {},
   "source": [
    "Create a **`StratifiedKFold` cross-validation** object. Then use it inside the\n",
    "**`cross_val_score`** function to evaluate the decision tree. We will first use\n",
    "the **accuracy as a score function**. **Explicitly use the `scoring` parameter**\n",
    "of `cross_val_score` to compute the accuracy (even if this is the default\n",
    "score). Check its documentation to learn how to do that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ccef687",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.44      , 0.58666667, 0.62      , 0.70469799, 0.69798658])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cv = StratifiedKFold()\n",
    "scores = cross_val_score(model, data, target, cv=cv, scoring='accuracy')\n",
    "\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb7b877",
   "metadata": {},
   "source": [
    "Repeat the experiment by **computing the `balanced_accuracy`**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "059fdaff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.4619883 , 0.50657895, 0.41374269, 0.60902256, 0.48258145])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cross_val_score(model, data, target, cv=cv, scoring='balanced_accuracy')\n",
    "\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd78e486",
   "metadata": {},
   "source": [
    "We now add a bit of complexity. We would like to **compute the precision**\n",
    "of our model. However, during the course we saw that we need to mention the\n",
    "**positive label** which in our case we consider to be the class **`donated`**.\n",
    "\n",
    "We show that computing the precision without providing the positive\n",
    "label will not be supported by scikit-learn because it is indeed ambiguous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c75ad44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:696: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 687, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 87, in __call__\n",
      "    score = scorer._score(cached_call, estimator,\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 242, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred,\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1656, in precision_score\n",
      "    p, _, _, _ = precision_recall_fscore_support(y_true, y_pred,\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1464, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels,\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1285, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: pos_label=1 is not a valid label. It should be one of ['donated', 'not donated']\n",
      "\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:696: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 687, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 87, in __call__\n",
      "    score = scorer._score(cached_call, estimator,\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 242, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred,\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1656, in precision_score\n",
      "    p, _, _, _ = precision_recall_fscore_support(y_true, y_pred,\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1464, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels,\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1285, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: pos_label=1 is not a valid label. It should be one of ['donated', 'not donated']\n",
      "\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:696: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 687, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 87, in __call__\n",
      "    score = scorer._score(cached_call, estimator,\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 242, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred,\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1656, in precision_score\n",
      "    p, _, _, _ = precision_recall_fscore_support(y_true, y_pred,\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1464, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels,\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1285, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: pos_label=1 is not a valid label. It should be one of ['donated', 'not donated']\n",
      "\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:696: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 687, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 87, in __call__\n",
      "    score = scorer._score(cached_call, estimator,\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 242, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred,\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1656, in precision_score\n",
      "    p, _, _, _ = precision_recall_fscore_support(y_true, y_pred,\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1464, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels,\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1285, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: pos_label=1 is not a valid label. It should be one of ['donated', 'not donated']\n",
      "\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:696: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 687, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 87, in __call__\n",
      "    score = scorer._score(cached_call, estimator,\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 242, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred,\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1656, in precision_score\n",
      "    p, _, _, _ = precision_recall_fscore_support(y_true, y_pred,\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1464, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels,\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1285, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: pos_label=1 is not a valid label. It should be one of ['donated', 'not donated']\n",
      "\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:696: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 687, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 87, in __call__\n",
      "    score = scorer._score(cached_call, estimator,\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 242, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred,\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1656, in precision_score\n",
      "    p, _, _, _ = precision_recall_fscore_support(y_true, y_pred,\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1464, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels,\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1285, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: pos_label=1 is not a valid label. It should be one of ['donated', 'not donated']\n",
      "\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:696: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 687, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 87, in __call__\n",
      "    score = scorer._score(cached_call, estimator,\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 242, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred,\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1656, in precision_score\n",
      "    p, _, _, _ = precision_recall_fscore_support(y_true, y_pred,\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1464, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels,\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1285, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: pos_label=1 is not a valid label. It should be one of ['donated', 'not donated']\n",
      "\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:696: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 687, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 87, in __call__\n",
      "    score = scorer._score(cached_call, estimator,\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 242, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred,\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1656, in precision_score\n",
      "    p, _, _, _ = precision_recall_fscore_support(y_true, y_pred,\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1464, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels,\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1285, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: pos_label=1 is not a valid label. It should be one of ['donated', 'not donated']\n",
      "\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:696: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 687, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 87, in __call__\n",
      "    score = scorer._score(cached_call, estimator,\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 242, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred,\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1656, in precision_score\n",
      "    p, _, _, _ = precision_recall_fscore_support(y_true, y_pred,\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1464, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels,\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1285, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: pos_label=1 is not a valid label. It should be one of ['donated', 'not donated']\n",
      "\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:696: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 687, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 87, in __call__\n",
      "    score = scorer._score(cached_call, estimator,\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 242, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred,\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1656, in precision_score\n",
      "    p, _, _, _ = precision_recall_fscore_support(y_true, y_pred,\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1464, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels,\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1285, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: pos_label=1 is not a valid label. It should be one of ['donated', 'not donated']\n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "tree = DecisionTreeClassifier()\n",
    "try:\n",
    "    scores = cross_val_score(tree, data, target, cv=10, scoring=\"precision\")\n",
    "except ValueError as exc:\n",
    "    print(exc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7342841",
   "metadata": {},
   "source": [
    "<div class=\"admonition tip alert alert-warning\">\n",
    "<p class=\"first admonition-title\" style=\"font-weight: bold;\">Tip</p>\n",
    "<p class=\"last\">We catch the exception with a <tt class=\"docutils literal\">try</tt>/<tt class=\"docutils literal\">except</tt> pattern to be able to print it.</p>\n",
    "</div>\n",
    "\n",
    "We get an exception because the **default scorer** has its **positive label set to\n",
    "one (`pos_label=1`)**, which is not our case (**our positive label is \"donated\"**).\n",
    "In this case, we need to **create a scorer** using the **scoring function** and the\n",
    "**helper function `make_scorer`**.\n",
    "\n",
    "So, **import `sklearn.metrics.make_scorer`** and\n",
    "**`sklearn.metrics.precision_score`**. Check their documentations for more\n",
    "information.\n",
    "Finally, **create a scorer** by calling **`make_scorer`** using the **score function\n",
    "`precision_score`** and pass the **extra parameter `pos_label=\"donated\"`**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c8a8c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer, precision_score\n",
    "\n",
    "scorer = make_scorer(precision_score, pos_label='donated')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e38943",
   "metadata": {},
   "source": [
    "Now, instead of providing the string `\"precision\"` to the `scoring` parameter\n",
    "in the `cross_val_score` call, pass the scorer that you created above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d3a8267",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.2173913 , 0.20512821, 0.08      , 0.4       , 0.19047619])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scorer2 = cross_val_score(model, data, target, cv=cv, scoring=scorer)\n",
    "scorer2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24b99a3",
   "metadata": {},
   "source": [
    "`cross_val_score` will only compute a single score provided to the `scoring`\n",
    "parameter. The function `cross_validate` allows the **computation of multiple\n",
    "scores by passing a list of strings or scorers to the parameter `scoring`**,\n",
    "which could be handy.\n",
    "\n",
    "Import `sklearn.model_selection.cross_validate` and compute the **accuracy** and\n",
    "**balanced accuracy** through cross-validation. **Plot** the cross-validation score\n",
    "for both **metrics using a box plot**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3bfb6899",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "cv_res = cross_validate(model, data, target, cv=cv, scoring=['accuracy', 'balanced_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df777486",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.00655603, 0.00263286, 0.00258207, 0.00249171, 0.00249147]),\n",
       " 'score_time': array([0.00243735, 0.00198174, 0.00188589, 0.00188208, 0.001863  ]),\n",
       " 'test_accuracy': array([0.41333333, 0.6       , 0.6       , 0.69798658, 0.69127517]),\n",
       " 'test_balanced_accuracy': array([0.4619883 , 0.48026316, 0.41374269, 0.59473684, 0.49135338])}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5d86d026",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "ax = sns.boxplot(x=cv_res['test_accuracy'])\n",
    "sns.boxplot(x=cv_res['test_balanced_accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20d385a",
   "metadata": {},
   "source": [
    "Balanced accuracy is significantly lower than the accuracy score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6faa22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "nbreset": "https://github.com/INRIA/scikit-learn-mooc/raw/master/notebooks/metrics_ex_01.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
