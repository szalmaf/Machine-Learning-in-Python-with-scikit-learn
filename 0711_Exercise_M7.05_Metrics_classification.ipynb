{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7619ae20",
   "metadata": {},
   "source": [
    "# üìù Exercise M7.02\n",
    "\n",
    "We **presented different classification metrics** in the previous notebook.\n",
    "However, we **did not use it with a cross-validation**. This exercise aims at\n",
    "practicing and implementing cross-validation.\n",
    "\n",
    "We will reuse the **blood transfusion dataset**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "784ce3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "blood_transfusion = pd.read_csv(\"../datasets/blood_transfusion.csv\")\n",
    "data = blood_transfusion.drop(columns=\"Class\")\n",
    "target = blood_transfusion[\"Class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a24d2f5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        donated\n",
       "1        donated\n",
       "2        donated\n",
       "3        donated\n",
       "4    not donated\n",
       "Name: Class, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7d4893d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "not donated    0.762032\n",
       "donated        0.237968\n",
       "Name: Class, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7215b23a",
   "metadata": {},
   "source": [
    "<div class=\"admonition note alert alert-info\">\n",
    "<p class=\"first admonition-title\" style=\"font-weight: bold;\">Note</p>\n",
    "<p class=\"last\">If you want a deeper overview regarding this dataset, you can refer to the\n",
    "Appendix - Datasets description section at the end of this MOOC.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976a4fef",
   "metadata": {},
   "source": [
    "First, create a decision tree classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9163698",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "model = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ab57de",
   "metadata": {},
   "source": [
    "Create a **`StratifiedKFold` cross-validation** object. Then use it inside the\n",
    "**`cross_val_score`** function to evaluate the decision tree. We will first use\n",
    "the **accuracy as a score function**. **Explicitly use the `scoring` parameter**\n",
    "of `cross_val_score` to compute the accuracy (even if this is the default\n",
    "score). Check its documentation to learn how to do that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ccef687",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.42666667, 0.6       , 0.61333333, 0.70469799, 0.69127517])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cv = StratifiedKFold()\n",
    "scores = cross_val_score(model, data, target, cv=cv, scoring='accuracy')\n",
    "\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb7b877",
   "metadata": {},
   "source": [
    "Repeat the experiment by **computing the `balanced_accuracy`**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "059fdaff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.48026316, 0.4751462 , 0.41374269, 0.61892231, 0.50125313])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cross_val_score(model, data, target, cv=cv, scoring='balanced_accuracy')\n",
    "\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd78e486",
   "metadata": {},
   "source": [
    "We now add a bit of complexity. We would like to **compute the precision**\n",
    "of our model. However, during the course we saw that we need to mention the\n",
    "**positive label** which in our case we consider to be the class **`donated`**.\n",
    "\n",
    "We show that computing the precision without providing the positive\n",
    "label will not be supported by scikit-learn because it is indeed ambiguous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c75ad44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:696: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 687, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 87, in __call__\n",
      "    score = scorer._score(cached_call, estimator,\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 242, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred,\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1656, in precision_score\n",
      "    p, _, _, _ = precision_recall_fscore_support(y_true, y_pred,\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1464, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels,\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1285, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: pos_label=1 is not a valid label. It should be one of ['donated', 'not donated']\n",
      "\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:696: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 687, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 87, in __call__\n",
      "    score = scorer._score(cached_call, estimator,\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 242, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred,\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1656, in precision_score\n",
      "    p, _, _, _ = precision_recall_fscore_support(y_true, y_pred,\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1464, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels,\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1285, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: pos_label=1 is not a valid label. It should be one of ['donated', 'not donated']\n",
      "\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:696: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 687, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 87, in __call__\n",
      "    score = scorer._score(cached_call, estimator,\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 242, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred,\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1656, in precision_score\n",
      "    p, _, _, _ = precision_recall_fscore_support(y_true, y_pred,\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1464, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels,\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1285, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: pos_label=1 is not a valid label. It should be one of ['donated', 'not donated']\n",
      "\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:696: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 687, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 87, in __call__\n",
      "    score = scorer._score(cached_call, estimator,\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 242, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred,\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1656, in precision_score\n",
      "    p, _, _, _ = precision_recall_fscore_support(y_true, y_pred,\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1464, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels,\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1285, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: pos_label=1 is not a valid label. It should be one of ['donated', 'not donated']\n",
      "\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:696: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 687, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 87, in __call__\n",
      "    score = scorer._score(cached_call, estimator,\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 242, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred,\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1656, in precision_score\n",
      "    p, _, _, _ = precision_recall_fscore_support(y_true, y_pred,\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1464, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels,\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1285, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: pos_label=1 is not a valid label. It should be one of ['donated', 'not donated']\n",
      "\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:696: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 687, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 87, in __call__\n",
      "    score = scorer._score(cached_call, estimator,\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 242, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred,\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1656, in precision_score\n",
      "    p, _, _, _ = precision_recall_fscore_support(y_true, y_pred,\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1464, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels,\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1285, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: pos_label=1 is not a valid label. It should be one of ['donated', 'not donated']\n",
      "\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:696: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 687, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 87, in __call__\n",
      "    score = scorer._score(cached_call, estimator,\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 242, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred,\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1656, in precision_score\n",
      "    p, _, _, _ = precision_recall_fscore_support(y_true, y_pred,\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1464, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels,\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1285, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: pos_label=1 is not a valid label. It should be one of ['donated', 'not donated']\n",
      "\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:696: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 687, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 87, in __call__\n",
      "    score = scorer._score(cached_call, estimator,\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 242, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred,\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1656, in precision_score\n",
      "    p, _, _, _ = precision_recall_fscore_support(y_true, y_pred,\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1464, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels,\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1285, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: pos_label=1 is not a valid label. It should be one of ['donated', 'not donated']\n",
      "\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:696: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 687, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 87, in __call__\n",
      "    score = scorer._score(cached_call, estimator,\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 242, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred,\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1656, in precision_score\n",
      "    p, _, _, _ = precision_recall_fscore_support(y_true, y_pred,\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1464, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels,\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1285, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: pos_label=1 is not a valid label. It should be one of ['donated', 'not donated']\n",
      "\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:696: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 687, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 87, in __call__\n",
      "    score = scorer._score(cached_call, estimator,\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 242, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred,\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1656, in precision_score\n",
      "    p, _, _, _ = precision_recall_fscore_support(y_true, y_pred,\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1464, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels,\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1285, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: pos_label=1 is not a valid label. It should be one of ['donated', 'not donated']\n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "tree = DecisionTreeClassifier()\n",
    "try:\n",
    "    scores = cross_val_score(tree, data, target, cv=10, scoring=\"precision\")\n",
    "except ValueError as exc:\n",
    "    print(exc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7342841",
   "metadata": {},
   "source": [
    "<div class=\"admonition tip alert alert-warning\">\n",
    "<p class=\"first admonition-title\" style=\"font-weight: bold;\">Tip</p>\n",
    "<p class=\"last\">We catch the exception with a <tt class=\"docutils literal\">try</tt>/<tt class=\"docutils literal\">except</tt> pattern to be able to print it.</p>\n",
    "</div>\n",
    "\n",
    "We get an exception because the **default scorer** has its **positive label set to\n",
    "one (`pos_label=1`)**, which is not our case (**our positive label is \"donated\"**).\n",
    "In this case, we need to **create a scorer** using the **scoring function** and the\n",
    "**helper function `make_scorer`**.\n",
    "\n",
    "So, **import `sklearn.metrics.make_scorer`** and\n",
    "**`sklearn.metrics.precision_score`**. Check their documentations for more\n",
    "information.\n",
    "Finally, **create a scorer** by calling **`make_scorer`** using the **score function\n",
    "`precision_score`** and pass the **extra parameter `pos_label=\"donated\"`**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c8a8c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer, precision_score\n",
    "\n",
    "scorer = make_scorer(precision_score, pos_label='donated')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e38943",
   "metadata": {},
   "source": [
    "Now, instead of providing the string `\"precision\"` to the `scoring` parameter\n",
    "in the `cross_val_score` call, pass the scorer that you created above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d3a8267",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.2173913 , 0.2195122 , 0.06896552, 0.34285714, 0.2       ])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scorer2 = cross_val_score(model, data, target, cv=cv, scoring=scorer)\n",
    "scorer2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24b99a3",
   "metadata": {},
   "source": [
    "`cross_val_score` will only compute a single score provided to the `scoring`\n",
    "parameter. The function `cross_validate` allows the **computation of multiple\n",
    "scores by passing a list of strings or scorers to the parameter `scoring`**,\n",
    "which could be handy.\n",
    "\n",
    "Import `sklearn.model_selection.cross_validate` and compute the **accuracy** and\n",
    "**balanced accuracy** through cross-validation. **Plot** the cross-validation score\n",
    "for both **metrics using a box plot**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3bfb6899",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "cv_res = cross_validate(model, data, target, cv=cv, scoring=['accuracy', 'balanced_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df777486",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.00251889, 0.00251055, 0.00252986, 0.00249171, 0.00249815]),\n",
       " 'score_time': array([0.00206041, 0.00201535, 0.00190115, 0.00190592, 0.00187802]),\n",
       " 'test_accuracy': array([0.41333333, 0.63333333, 0.6       , 0.70469799, 0.67785235]),\n",
       " 'test_balanced_accuracy': array([0.4619883 , 0.50219298, 0.41374269, 0.61892231, 0.48258145])}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d86d026",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "ax = sns.boxplot(x=cv_res['test_accuracy'])\n",
    "sns.boxplot(x=cv_res['test_balanced_accuracy'], color='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20d385a",
   "metadata": {},
   "source": [
    "Balanced accuracy is significantly lower than the accuracy score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6faa22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "nbreset": "https://github.com/INRIA/scikit-learn-mooc/raw/master/notebooks/metrics_ex_01.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
